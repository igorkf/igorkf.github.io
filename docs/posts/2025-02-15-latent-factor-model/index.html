<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-02-23">

<title>Factor analysis from scratch: theory and code – Igor Kuivjogi Fernandes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-3BCPXRWVV0"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-3BCPXRWVV0', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Factor analysis from scratch: theory and code – Igor Kuivjogi Fernandes">
<meta property="og:description" content="">
<meta property="og:image" content="https://igorkf.github.io/posts/2025-02-15-latent-factor-model/images/art.jpg">
<meta property="og:site_name" content="Igor Kuivjogi Fernandes">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Igor Kuivjogi Fernandes</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../posts/index.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/igorkf/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/igorkuivjogi/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://scholar.google.com/citations?user=fo6kWzgAAAAJ&amp;hl=en&amp;oi=ao"> <i class="bi bi-google" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Factor analysis from scratch: theory and code</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">multivariate-analysis</div>
                <div class="quarto-category">latent-variables</div>
                <div class="quarto-category">factor-analysis</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 23, 2025</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">February 23, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>In this post, I am going to derive some mathematical results of the latent factor model (a.k.a factor analysis) and then implement it from scratch, comparing it with a known implementation from the <code>psych</code> package. The idea here is not to run a full factor analysis and interpret the results, but rather to get to know better the math behind it.</p>
<p>One reason to run factor analysis is to study the linear association between variables. In factor analysis, we assume that this linear association may exist because the variables are functions of a small group of unobserved variables known as <em>latent factors</em>. Let’s derive this idea.</p>
<section id="mathematical-notation" class="level1">
<h1>Mathematical notation</h1>
<p>Consider we have <span class="math inline">\(p\)</span> variables represented by <span class="math inline">\(X\)</span>, and all variables are standardized (centered by their mean, and scaled by their standard deviation), such that each variable has zero mean and unit variance:</p>
<p><span class="math display">\[
X = \begin{bmatrix}
x_1 \dots x_p
\end{bmatrix}^T
\]</span></p>
<p>with mean vector <span class="math inline">\(E[X] = \mu = [0 \dots 0]^T\)</span> and covariance matrix <span class="math inline">\(D[X] = \Sigma\)</span>. So, through this post, <span class="math inline">\(D[.]\)</span> will be used to denote the covariance matrix.</p>
<p>Due to the standardization of variables, <span class="math inline">\(D[X]\)</span> has the following properties:</p>
<ol type="i">
<li><p>Diagonal values (the variances) are one</p></li>
<li><p>Off-diagonal (the covariances) are <span class="math inline">\(\sigma_{ij} = Cov[x_i, x_j] = Corr[x_i, x_j]\)</span> for all <span class="math inline">\(i \ne j\)</span>, because <span class="math inline">\(Corr[x_i, x_j] = \frac{Cov[x_i, x_j]}{\sqrt{Var[x_i]} \sqrt{Var[x_j]}} = \frac{Cov[x_i, x_j]}{\sqrt{1} \sqrt{1}} = Cov[x_i, x_j]\)</span></p></li>
</ol>
<p>This means after standardization we are working with a correlation matrix.</p>
<p>Define a vector <span class="math inline">\(f\)</span> of random variables that we have not observed:</p>
<p><span class="math display">\[
f = \begin{bmatrix}
f_1 \dots f_k
\end{bmatrix}^T
\]</span> with <span class="math inline">\(k \ll n\)</span> and <span class="math inline">\(k \ll p\)</span>. By now, let’s assume we know <span class="math inline">\(k\)</span>.</p>
<p>Now we can start relating <span class="math inline">\(X\)</span> with <span class="math inline">\(f\)</span>. Each variable <span class="math inline">\(x_i\)</span> is related to <span class="math inline">\(f\)</span> as follows:</p>
<p><span class="math display">\[
\begin{align*}
x_1 =&amp; L_{11} f_1 + L_{12} f_2 + \dots + L_{1k} f_k + \varepsilon_1 \\
x_2 =&amp; L_{21} f_1 + L_{22} f_2 + \dots + L_{2k} f_k + \varepsilon_2 \\
\vdots \\
x_p =&amp; L_{p1} f_1 + L_{p2} f_2 + \dots + L_{pk} f_k + \varepsilon_p
\end{align*}
\]</span></p>
<p>where the coefficients multiplying each component of <span class="math inline">\(f\)</span> are fixed unknown parameters that need to be estimated, and <span class="math inline">\(\varepsilon_1 \dots \varepsilon_p\)</span> are random errors. They represent the parts of <span class="math inline">\(x_1 \dots x_p\)</span> that cannot be linearly explained by <span class="math inline">\(f_1 \dots f_k\)</span>. As you can see, each variable is written as a linear combination of the factors plus a portion not explained by them.</p>
<p>This system of equations can be represented in a matrix form as:</p>
<p><span class="math display">\[
\begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_p
\end{bmatrix} = \begin{bmatrix}
L_{11} &amp; L_{12} &amp; \dots &amp; L_{1k} \\
L_{21} &amp; L_{22} &amp; \dots &amp; L_{2k} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
L_{p1} &amp; L_{p2} &amp; \dots &amp; L_{pk}
\end{bmatrix}
\begin{bmatrix}
f_1 \\
f_2 \\
\vdots \\
f_k
\end{bmatrix}
\]</span></p>
<p>This can be written as:</p>
<p><span class="math display">\[
X = L f + \varepsilon
\]</span></p>
<p>where <span class="math inline">\(X\)</span> is a <span class="math inline">\(p \times 1\)</span> vector, <span class="math inline">\(L\)</span> is a <span class="math inline">\(p \times k\)</span> matrix, <span class="math inline">\(f\)</span> is a <span class="math inline">\(k \times 1\)</span> vector, and <span class="math inline">\(\varepsilon\)</span> is a <span class="math inline">\(p \times 1\)</span> vector. The <span class="math inline">\(L\)</span> matrix is known as the <em>loading matrix</em> and the <span class="math inline">\(f\)</span> vector is known as the <em>factor scores</em>.</p>
<p>Notice that all terms in the right-hand side of the equation are unknown, where <span class="math inline">\(L\)</span> is a matrix of fixed unknown parameters (that we need to estimate) and <span class="math inline">\(f\)</span> and <span class="math inline">\(\varepsilon\)</span> are unknown random vectors.</p>
<p>Further assumptions for <span class="math inline">\(f\)</span> and <span class="math inline">\(\varepsilon\)</span> are:</p>
<p><span class="math display">\[
E[f] = \begin{bmatrix}
0 \dots 0
\end{bmatrix}^T, \ D[f] = I_k
\]</span></p>
<p>Notice that <span class="math inline">\(D[f] = I_k\)</span> implies that the factors are uncorrelated as we want to explain the linear correlation of <span class="math inline">\(X\)</span> variables using a set of non-correlated latent factors, otherwise the interpretation would be confounded. We further have that:</p>
<p><span class="math display">\[
E[\varepsilon] = \begin{bmatrix}
0 \dots 0
\end{bmatrix}^T, \ D[\varepsilon] = \begin{bmatrix}
\sigma_1^2 &amp; 0 &amp; \dots &amp; 0 \\
0 &amp; \sigma_2^2 &amp; \dots &amp; 0\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \dots &amp; \sigma_p^2 \\
\end{bmatrix}
\]</span></p>
<p>The last assumption is that <span class="math inline">\(f\)</span> and <span class="math inline">\(\varepsilon\)</span> are independent.</p>
</section>
<section id="the-correlation-matrix" class="level1">
<h1>The correlation matrix</h1>
<p>As stated in the beginning, we want to study the correlation between the variables, but using the equation we derived for <span class="math inline">\(X\)</span> that involves <span class="math inline">\(L\)</span> and <span class="math inline">\(f\)</span>. This correlation will be denoted as <span class="math inline">\(\Sigma\)</span>. From some properties of covariances, we have that:</p>
<p><span class="math display">\[
\begin{align*}
\Sigma =&amp; D[X] = D[Lf + \varepsilon] = Cov[Lf + \varepsilon, Lf + \varepsilon] \\
=&amp; \underbrace{Cov[Lf, Lf]}_{D[Lf]} + \underbrace{Cov[Lf, \varepsilon]}_0 + \underbrace{Cov[\varepsilon, Lf]}_0 + \underbrace{Cov[\varepsilon, \varepsilon]}_{D[\varepsilon]} \\
=&amp; D[Lf] + D[\varepsilon] = L D[f] L^T + D[\varepsilon] = L I_k L^T + D[\varepsilon] \\
=&amp; LL^T + D[\varepsilon]
\end{align*}
\]</span></p>
<p>Above, two terms are zero because we assumed <span class="math inline">\(f\)</span> and <span class="math inline">\(\varepsilon\)</span> are independent.</p>
<p>Remember that each variable has zero mean and unit variance, so all diagonal values of <span class="math inline">\(\Sigma\)</span> are one. It turns out there are some interesting results arising from the diagonal values of <span class="math inline">\(\Sigma\)</span>. Let <span class="math inline">\(\Sigma_{ii}\)</span> represent the i-th diagonal value from <span class="math inline">\(\Sigma\)</span>, so:</p>
<p><span class="math display">\[
\begin{align*}
\Sigma_{ii} =&amp; Var[x_i] = (LL^T + D[\varepsilon])_{ii} = 1 \implies \\
&amp; (LL^T)_{ii} + \underbrace{(D[\varepsilon])_{ii}}_{\sigma_i^2} = 1 \implies \\
&amp; (LL^T)_{ii} + \sigma_i^2 = 1
\end{align*}
\]</span></p>
<p>Note we can represent the i-th diagonal value from <span class="math inline">\(LL^T\)</span> as a dot product of <span class="math inline">\(L\)</span>’s i-th row:</p>
<p><span class="math display">\[
(LL^T)_{ii} = \begin{bmatrix}
L_{i1} \ L_{i2} \dots L_{ik}
\end{bmatrix} \begin{bmatrix}
L_{i1} \\
L_{i2} \\
\vdots \\
L_{ik}
\end{bmatrix}
\]</span></p>
<p>Plugging in into the result from before, we have:</p>
<p><span class="math display">\[
\begin{align*}
\Sigma_{ii} =&amp; \begin{bmatrix}
L_{i1} \ L_{i2} \dots L_{ik}
\end{bmatrix} \begin{bmatrix}
L_{i1} \\
L_{i2} \\
\vdots \\
L_{ik}
\end{bmatrix} + \sigma_i^2 = 1 \implies \\
&amp; L_{i1}^2 + L_{i2}^2 + \dots + L_{ik}^2 + \sigma_i^2 = 1 \implies \\
\sigma_i^2 &amp;= 1 - (L_{i1}^2 + L_{i2}^2 + \dots + L_{ik}^2)
\end{align*}
\]</span></p>
<p>This means that if we estimate <span class="math inline">\(L\)</span>, we can easily find <span class="math inline">\(D[\varepsilon]\)</span>. Arranging the result above, we have:</p>
<p><span class="math display">\[
\underbrace{\sigma_i^2}_{\text{non-negative}} + \ \underbrace{L_{i1}^2 + L_{i2}^2 + \dots + L_{ik}^2}_{\text{non-negative}} = 1
\]</span></p>
<p>As both quantities are non-negative, and they sum to one, we can think of them as two proportions (e.g., <span class="math inline">\(30\% + 70\% = 1\)</span> or <span class="math inline">\(84\% + 16\% = 1\)</span>).</p>
<!-- From above, two inequalities hold: -->
<!-- $$ -->
<!-- 0 \le \sigma_i^2 \le 1 \ \text{and} \ 0 \le L_{i1}^2 + L_{i2}^2 + \dots + L_{ik}^2 \le 1 -->
<!-- $$ -->
<p>As <span class="math inline">\(\Sigma = D[X] = LL^T + D[\varepsilon]\)</span>, where the i-th diagonal of <span class="math inline">\(\Sigma\)</span> is <span class="math inline">\(Var[x_i]\)</span>, we have that:</p>
<p><span class="math display">\[
\Sigma_{ii} = Var[x_i] = 1 = \underbrace{L_{i1}^2 + L_{i2}^2 + \dots + L_{ik}^2}_{\text{A}} + \underbrace{\sigma_i^2}_{\text{B}}
\]</span></p>
<p>where <span class="math inline">\(\text{A}\)</span> is the proportion of <span class="math inline">\(Var[x_i]\)</span> explained by the factors, also known as <em>communality</em> of <span class="math inline">\(x_i\)</span> and <span class="math inline">\(\text{B}\)</span> is the proportion of <span class="math inline">\(Var[x_i]\)</span> <strong>not</strong> explained by the factors, known as <em>specific variance</em> of <span class="math inline">\(Var[x_i]\)</span>. Of course, this result holds for all the variances <span class="math inline">\(Var[x_1], Var[X_2], \dots, Var[x_p]\)</span>. As <a href="https://www.youtube.com/@drpeyam">Dr.&nbsp;Peyam</a> would say, “how cool is that?!”. We can partition the variance of each variable in two parts.</p>
<!-- It can be shown that: -->
<!-- i) for any $(i, j)$, $L_{ij}^2$ is the proportion of $Var[x_i]$ explained by the $j-th$ factor -->
<!-- ii) for any $i$, the sum of squares of the i-th row of $L$ represent the proportion of $Var[x_i]$ explained by all factors together -->
<!-- iii) for any $j$, the sum of squares of entries of j-th column of $L$ represent the total variability of all $p$ variables explained by the j-th factor -->
</section>
<section id="one-property-of-the-loading-matrix" class="level1">
<h1>One property of the loading matrix</h1>
<p>There are many properties of the loading matrix <span class="math inline">\(L\)</span>, and they are used when performing a factor analysis, but let’s focus in one particular result. Pick any two variables, e.g., the i-th and the j-th, with <span class="math inline">\(i \neq j\)</span>. As defined previously:</p>
<p><span class="math display">\[
\begin{align*}
x_i =&amp; L_{i1} f_1 + L_{i2} f_2 + \dots + L_{ik} + \varepsilon_i \\
x_j =&amp; L_{j1} f_1 + L_{j2} f_2 + \dots + L_{jk} + \varepsilon_j
\end{align*}
\]</span></p>
<p>So, what is the correlation between <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> in terms of <span class="math inline">\(L\)</span>? To derive this result, we can first compute its covariance, and then its correlation:</p>
<p><span class="math display">\[
\begin{align*}
Cov[x_i, x_j] &amp;= Cov[
  L_{i1} f_1 + L_{i2} f_2 + \dots + L_{ik} + \varepsilon_i,
  L_{j1} f_1 + L_{j2} f_2 + \dots + L_{jk} + \varepsilon_j
] \\
&amp;= \text{Sum of covariances of all pairwise combinations}
\end{align*}
\]</span></p>
<p>Many terms of this sum will disappear because:</p>
<ul>
<li><p><span class="math inline">\(D[f] = I_k\)</span>, so any pair involving two different factors <span class="math inline">\(f_i\)</span> and <span class="math inline">\(f_j\)</span> will be uncorrelated</p></li>
<li><p><span class="math inline">\(f\)</span> and <span class="math inline">\(\varepsilon\)</span> were assumed to be independent, so any pair involving one factor and one member of <span class="math inline">\(\varepsilon\)</span> will be uncorrelated</p></li>
<li><p><span class="math inline">\(D[\varepsilon]\)</span> is a diagonal matrix, so any pair of different members of <span class="math inline">\(\varepsilon\)</span> will be uncorrelated</p></li>
</ul>
<p>Thus, the only non-zero terms are those involving the same pair of factors:</p>
<p><span class="math display">\[
\begin{align*}
Cov[x_i, x_j] &amp;= Cov[L_{i1} f_1, L_{j1} f_1] + Cov[L_{i2} f_2, L_{j2} f_2] + \dots + Cov[L_{ik} f_k, L_{jk} f_k] \\
&amp;= L_{i1} Cov[f_1, f_1] L_{j1} + L_{i2} Cov[f_2, f_2] L_{j2} + \dots + L_{ik} Cov[f_k, f_k] L_{jk} \\
&amp;= L_{i1} Var[f_1] L_{j1} + L_{i2} Var[f_2] L_{j2} + \dots + L_{ik} Var[f_k] L_{jk} \\
&amp;= L_{i1} L_{j1} + L_{i2} L_{j2} + \dots + L_{ik} L_{jk}
\end{align*}
\]</span> because <span class="math inline">\(D[f] = I_k\)</span>, so <span class="math inline">\(Var[f_1] = Var[f_2] = \dots = Var[f_k] = 1\)</span>. Now, the result above means that:</p>
<p><span class="math display">\[
\begin{align*}
Cov[x_i, x_j] &amp;= L_{i1} L_{j1} + L_{i2} L_{j2} + \dots + L_{ik} L_{jk} \\
&amp;= \text{Dot product between i-th and j-th rows of L} \\
&amp;= L_{i*}^T L_{j*}
\end{align*}
\]</span> Since <span class="math inline">\(Var[x_i] = Var[x_j] = 1\)</span>, we have that:</p>
<p><span class="math display">\[
Corr[x_i, x_j] = \frac{Cov[x_i, x_j]}{\sqrt{Var[x_i]} \sqrt{Var[x_j]}} = \frac{L_{i*}^T L_{j*}}{\sqrt{1} \sqrt{1}} = L_{i*}^T L_{j*}
\]</span> So, if we have <span class="math inline">\(L\)</span>, calculating <span class="math inline">\(Corr[x_i, x_j]\)</span> is just taking the dot product between i-th and j-th rows of <span class="math inline">\(L\)</span>.</p>
</section>
<section id="estimating-the-loading-matrix" class="level1">
<h1>Estimating the loading matrix</h1>
<p>There are many ways to estimate the loading matrix <span class="math inline">\(L\)</span>, and here we are going to use a principal component solution, which is also implemented in the <code>psych</code> package.</p>
<p>Actually, there is no <strong>unique</strong> solution for <span class="math inline">\(L\)</span>. To see this, consider any orthogonal matrix <span class="math inline">\(A\)</span>, so <span class="math inline">\(AA^T = A^TA = I_k\)</span>. Now, rewrite <span class="math inline">\(X\)</span> as:</p>
<p><span class="math display">\[
\begin{align*}
X &amp;= Lf + \varepsilon = L \underbrace{I_k}_{AA^T} f + \varepsilon \\
&amp;= \underbrace{(LA)}_{L^*} \underbrace{(A^Tf)}_{f^*} + \varepsilon = L^* f^* + \varepsilon
\end{align*}
\]</span></p>
<p>where properties of <span class="math inline">\(f^*\)</span> are still the same as the original <span class="math inline">\(f\)</span> because:</p>
<p><span class="math display">\[
E[f^*] = E[A^T f] = A^T \underbrace{E[f]}_{0} = 0
\]</span></p>
<p>and</p>
<p><span class="math display">\[
D[f^*] = D[A^T f] = A^T D[f] (A^T)^T = A^T I_k A = A^TA = I_k
\]</span> So, for any orthogonal matrix <span class="math inline">\(A\)</span>, using <span class="math inline">\(X = Lf + \varepsilon\)</span> or <span class="math inline">\(X = (LA)(A^Tf) + \varepsilon\)</span> is equivalent.</p>
<section id="the-connection-between-pca-and-factor-analysis" class="level2">
<h2 class="anchored" data-anchor-id="the-connection-between-pca-and-factor-analysis">The connection between PCA and factor analysis</h2>
<p>As mentioned, we are going to estimate <span class="math inline">\(L\)</span> using a principal components solution. Remember that the principal components representation for <span class="math inline">\(X\)</span>, where <span class="math inline">\(X\)</span> is written as a linear combination of the eigenvalues, is:</p>
<p><span class="math display">\[
Z = A_k (X - \mu) = A_k X
\]</span> because <span class="math inline">\(X\)</span> was standardized, with</p>
<p><span class="math display">\[
A_k = \begin{bmatrix}
u_1^T \\
\vdots \\
u_k^T
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(u_1^T, \dots, u_k^T\)</span> are the eigenvectors associated with the <span class="math inline">\(k\)</span> largest eigenvalues <span class="math inline">\(\lambda_{(1)}, \dots, \lambda_{(k)}\)</span> of <span class="math inline">\(D[X] = \Sigma\)</span>. Also, the variance of each principal component is <span class="math inline">\(\lambda_{(i)}\)</span>, and the principal components are uncorrelated, so:</p>
<p><span class="math display">\[
D[Z] =
\begin{bmatrix}
\lambda_{(1)} &amp; 0 &amp; \dots &amp; 0 \\
0 &amp; \lambda_{(2)} &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \dots &amp; \lambda_{(k)}
\end{bmatrix}
\]</span></p>
<p>Let <span class="math inline">\(X_R\)</span> represent the reconstruction of <span class="math inline">\(X\)</span> after performing PCA with <span class="math inline">\(k\)</span> components. It can be shown that this reconstruction is:</p>
<p><span class="math display">\[
X_R = \mu + A_K^T Z = A_k^T Z
\]</span></p>
<p>So, we can think of <span class="math inline">\(X\)</span> as a reconstruction plus an error of reconstruction:</p>
<p><span class="math display">\[
\begin{align*}
X &amp;= X_R + Error \\
&amp;= A_k^T Z + Error \\
\end{align*}
\]</span></p>
<p>This form is very similar to the latent factor model we derived before:</p>
<p><span class="math display">\[
X = L f + \varepsilon
\]</span></p>
<p>where <span class="math inline">\(A_k^T\)</span> would be the analogous of <span class="math inline">\(L\)</span> and <span class="math inline">\(Z\)</span> the analogous of <span class="math inline">\(f\)</span>. However, <span class="math inline">\(Z\)</span> cannot be used as <span class="math inline">\(f\)</span> because although <span class="math inline">\(E[f] = E[Z] = 0\)</span>, their covariance matrices are different, that is, <span class="math inline">\(D[f] = I_k \neq D[Z]\)</span>. To solve this, we can rescale <span class="math inline">\(Z\)</span> using the eigenvalues. Denote this rescaled version of <span class="math inline">\(Z\)</span> as <span class="math inline">\(Z^*\)</span>:</p>
<p><span class="math display">\[
Z^* = \begin{bmatrix}
z_1 / \sqrt{\lambda_{(1)}} \\
\vdots \\
z_k / \sqrt{\lambda_{(k)}} \\
\end{bmatrix}
\]</span></p>
<p>We still have <span class="math inline">\(E[Z^*] = E[Z] = 0\)</span> and now, for every <span class="math inline">\(i = 1, \dots, k\)</span>:</p>
<p><span class="math display">\[
Var\Big[\frac{z_i}{\sqrt{\lambda_{(i)}}}\Big] = \frac{1}{(\sqrt{\lambda_{(i)}})^2} Var[z_i] = \frac{\lambda_{(i)}}{\lambda_{(i)}} = 1
\]</span></p>
<p>and, as <span class="math inline">\(z_i\)</span> and <span class="math inline">\(z_j\)</span> are uncorrelated, so is <span class="math inline">\(z_i^* = z_i / \lambda_{(i)}\)</span> and <span class="math inline">\(z_j^* = z_j / \lambda_{(j)}\)</span>. Therefore, <span class="math inline">\(D[Z^*] = I_k = D[f]\)</span>. Thus, we have that <span class="math inline">\(Z^*\)</span> and <span class="math inline">\(f\)</span> share the same properties.</p>
<p>Coming back to <span class="math inline">\(X\)</span> after performing PCA, we need to rearrange the equation until we move from <span class="math inline">\(Z\)</span> to <span class="math inline">\(Z^*\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
X =&amp; A_k^T Z + Error \\
=&amp; \begin{bmatrix}
u_1^T \\
\vdots \\
u_k^T
\end{bmatrix}^T \begin{bmatrix}
z_1 \\
\vdots \\
z_k
\end{bmatrix} + Error \\
=&amp; \begin{bmatrix}
u_1 \dots u_k
\end{bmatrix} \begin{bmatrix}
z_1 \\
\vdots \\
z_k
\end{bmatrix} + Error \\
=&amp; \begin{bmatrix}
\sqrt{\lambda_{(1)}} u_1 \dots \sqrt{\lambda_{(k)}} u_k
\end{bmatrix} \begin{bmatrix}
z_1 / \sqrt{\lambda_{(1)}} \\
\vdots \\
z_k / \sqrt{\lambda_{(k)}} \\
\end{bmatrix} + Error \\
=&amp; \begin{bmatrix}
\sqrt{\lambda_{(1)}} u_1 \dots \sqrt{\lambda_{(k)}} u_k
\end{bmatrix} Z^* + Error
\end{align*}
\]</span></p>
<p>Match this result against the factor latent model <span class="math inline">\(X = Lf + \varepsilon\)</span>. We can see that <span class="math inline">\(Z^*\)</span> is playing the role of <span class="math inline">\(f\)</span>, in which <span class="math inline">\(Z^*\)</span> and <span class="math inline">\(f\)</span> have same the mean and covariance, and the vector pre-multiplying <span class="math inline">\(Z^*\)</span> is playing the role of <span class="math inline">\(L\)</span>. Thus, the solution for <span class="math inline">\(L\)</span> is:</p>
<p><span class="math display">\[
L = \begin{bmatrix}
\sqrt{\lambda_{(1)}} u_1 \dots \sqrt{\lambda_{(k)}} u_k
\end{bmatrix}
\]</span></p>
<p>So, to estimate <span class="math inline">\(L\)</span> we need to compute eigenvalues and eigenvectors of the covariance matrix of <span class="math inline">\(X\)</span>, and then construct <span class="math inline">\(L\)</span> using the square root of the <span class="math inline">\(k\)</span> largest eigenvalues associated with their eigenvectors.</p>
</section>
</section>
<section id="computing-the-latent-factors" class="level1">
<h1>Computing the latent factors</h1>
<p>There are different ways of computing the latent factors, and here we are going to use the Bartlett’s method, which is also implemented in the package <code>psych</code>. It can be shown that the vector of latent factors (or factor scores) for the i-th observation can be computed as:</p>
<p><span class="math display">\[
f^{(i)} = (L^T D[\varepsilon]^{-1} L)^{-1} L^T D[\varepsilon]^{-1} X^{(i)}
\]</span></p>
<p>where <span class="math inline">\(X^{(i)}\)</span> is the vector of <span class="math inline">\(p\)</span> variables for the i-th observation of our data. Note that once we have <span class="math inline">\(L\)</span>, we can easily find <span class="math inline">\(D[\varepsilon]\)</span> (as shown before), and, as <span class="math inline">\(D[\varepsilon]\)</span> is a diagonal matrix, we just need the reciprocal of the diagonal values to compute <span class="math inline">\(D[\varepsilon]^{-1}\)</span>.</p>
<p>Also, notice that this solution can be seen as a weighted least squares (WLS), with <span class="math inline">\(D[\varepsilon]\)</span> playing the role of the weight matrix.</p>
</section>
<section id="implementation" class="level1">
<h1>Implementation</h1>
<p>Now we are going to implement everything we saw here, and compare the results with the function <code>psych::fa</code>. We are going to use the principal components solution for estimating the loading matrix <span class="math inline">\(L\)</span> and Bartlett’s method for the latent factors <span class="math inline">\(f\)</span>.</p>
<p>We are going to use a dataset from the <code>psych</code> package called <code>bfi</code>. As this is just an example, let’s keep only the first five variables and remove the missing values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to read more about it, run ?psych::bfi </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>tab <span class="ot">&lt;-</span> psych<span class="sc">::</span>bfi[, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>tab <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(tab)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(tab)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ncol</span>(tab)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>n</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2709</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
</div>
<p>The implementation from scratch to estimate the loading matrix is:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize X</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">scale</span>(tab)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">2</span>  <span class="co"># number of factors (your choice)</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate the p x p correlation matrix, as X is standardized</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>Sigma <span class="ot">&lt;-</span> <span class="fu">cov</span>(X)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># computing eigenvalues and corresponding eigenvectors</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># and keeping the first k</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>eig <span class="ot">&lt;-</span> <span class="fu">eigen</span>(Sigma)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>eig<span class="sc">$</span>values <span class="ot">&lt;-</span> eig<span class="sc">$</span>values[<span class="dv">1</span><span class="sc">:</span>k]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>eig<span class="sc">$</span>vectors <span class="ot">&lt;-</span> eig<span class="sc">$</span>vectors[, <span class="dv">1</span><span class="sc">:</span>k, drop <span class="ot">=</span> F]</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># principal components solution for the loading matrix</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>L <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, p, k)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>  L[, j] <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(eig<span class="sc">$</span>values[j]) <span class="sc">*</span> eig<span class="sc">$</span>vectors[, j]</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>L</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]       [,2]
[1,]  0.5090648  0.8009641
[2,] -0.7638798 -0.1483181
[3,] -0.7979711  0.1195301
[4,] -0.6137605  0.3694111
[5,] -0.7162222  0.2777467</code></pre>
</div>
</div>
<p>Now, compare this to the implementation of <code>psych::fa</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>fac <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">fa</span>(</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  tab, <span class="at">nfactors =</span> k, <span class="at">fm =</span> <span class="st">"pa"</span>, <span class="at">scores =</span> <span class="st">"Bartlett"</span>, </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">rotate =</span> <span class="st">"none"</span>, <span class="at">correct =</span> <span class="dv">0</span>, <span class="at">max.iter =</span> <span class="dv">1</span>, <span class="at">smooth =</span> F, <span class="at">SMC =</span> F</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>fac<span class="sc">$</span>loadings[]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          PA1        PA2
A1 -0.5090648  0.8009641
A2  0.7638798 -0.1483181
A3  0.7979711  0.1195301
A4  0.6137605  0.3694111
A5  0.7162222  0.2777467</code></pre>
</div>
</div>
<p>We have exactly the same solution, except that the sign of the first column is flipped. As stated in <code>?psych::fa</code>, “the order of factors and the sign of some factors may differ”. This happens because the principal components solution for estimating <span class="math inline">\(L\)</span> uses eigenvectors, and eigenvectors are sign-invariant, i.e., if <span class="math inline">\(u_1\)</span> is an eigenvector, then <span class="math inline">\(-u_1\)</span> is also an eigenvector for the same corresponding eigenvalue.</p>
<p>As shown before, to calculate the correlation between first and second variables, for example, we just take the dot product between first and second rows of <span class="math inline">\(L\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>L[<span class="dv">1</span>, ] <span class="sc">%*%</span> L[<span class="dv">2</span>, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]
[1,] -0.5076618</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># comparing to psych::fa</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>fac<span class="sc">$</span>loadings[<span class="dv">1</span>, ] <span class="sc">%*%</span> fac<span class="sc">$</span>loadings[<span class="dv">2</span>, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]
[1,] -0.5076618</code></pre>
</div>
</div>
<p>The implementation to compute the factor scores is:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get D from L</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>D <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, p, p)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>p) {</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  D[i, i] <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> (L[i, ] <span class="sc">%*%</span> L[i, ])</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># predicting factor scores f for each observation using Bartlett's method (WLS)</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>Dinv <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">diag</span>(D), p, p)  <span class="co"># D is a diagonal matrix</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>LtDinv <span class="ot">&lt;-</span> <span class="fu">t</span>(L) <span class="sc">%*%</span> Dinv</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>LtDinvL_inv <span class="ot">&lt;-</span> <span class="fu">solve</span>(LtDinv <span class="sc">%*%</span> L)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, n, k)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n) {</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  f[i, ] <span class="ot">&lt;-</span> LtDinvL_inv <span class="sc">%*%</span> LtDinv <span class="sc">%*%</span> X[i, ]</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co"># f &lt;- X %*% t(LtDinv) %*% LtDinvL_inv  # or without a for loop</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>f[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]  <span class="co"># checking some values</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]       [,2]
[1,]  0.8273217 -0.8253666
[2,]  0.3337149 -0.5968593
[3,]  0.7407271  1.7405258
[4,] -0.1251758  1.5002035
[5,]  0.8080498 -0.6947279</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>f[<span class="dv">500</span><span class="sc">:</span><span class="dv">505</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]  <span class="co"># checking some values</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]        [,2]
[1,] -0.4507422  0.01231911
[2,] -0.7031572 -0.82334666
[3,] -0.1849710 -1.04894593
[4,] -1.4906012 -0.27790350
[5,] -0.3968627  0.79517651
[6,] -0.7522656  1.76471797</code></pre>
</div>
</div>
<p>Comparing to the implementation of <code>psych::fa</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>fac<span class="sc">$</span>scores[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             PA1        PA2
61617 -0.8273217 -0.8253666
61618 -0.3337149 -0.5968593
61620 -0.7407271  1.7405258
61621  0.1251758  1.5002035
61622 -0.8080498 -0.6947279</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>fac<span class="sc">$</span>scores[<span class="dv">500</span><span class="sc">:</span><span class="dv">505</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            PA1         PA2
62687 0.4507422  0.01231911
62688 0.7031572 -0.82334666
62690 0.1849710 -1.04894593
62692 1.4906012 -0.27790350
62694 0.3968627  0.79517651
62698 0.7522656  1.76471797</code></pre>
</div>
</div>
<p>Again, all values are exactly the same, except for the sign of first column.</p>
</section>
<section id="final-words" class="level1">
<h1>Final words</h1>
<p>The idea of this post was to show some mathematical results from factor analyis I saw during graduate school. There are plenty of tutorials on the internet to actually run a factor analysis and interpret results, but the point here was to derive the solution for important objects in factor analysis such as the loading matrix, the factor scores, and the covariance of errors.</p>
<p>There is much more to talk about such as rotations, proportion of explained variance by the factor scores, correlation between original variables and factor scores, and how to choose the number of factors (<span class="math inline">\(k\)</span>). However, I think this is enough to get a good grasp of this topic.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/igorkf\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="igorkf/igorkf.github.io" data-repo-id="R_kgDOJLX0KA" data-category="Blog" data-category-id="" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Blog made with <a href="https://quarto.org/">Quarto</a>, by Igor Kuivjogi Fernandes. License: <a href="https://creativecommons.org/licenses/by-sa/2.0/">CC BY-SA 2.0</a>.</p>
</div>   
    <div class="nav-footer-center">

<div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>